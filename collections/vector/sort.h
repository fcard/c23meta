#ifndef C23META_VECTOR_SORT
#define C23META_VECTOR_SORT

#define VECTOR32_SORT(LT,X) _VECTOR32_SORT_C(LT,X)
#define _VECTOR32_SORT_C(LT,X)\
  _VECTOR32_SORT(\
    CAT(_VECTOR32_SORT,VECTOR32_LENGTH(X)),\
    LT,\
    VECTOR32_LENGTH(X),\
    VECTOR32_UNWRAP(X))
#define _VECTOR32_SORT(F,LT,LEN,...) (LEN,F(LT __VA_OPT__(,) __VA_ARGS__))

#define _VECTOR32_SORT0(LT,...) ()
#define _VECTOR32_SORT1(LT,X0) (X0)

#define _VECTOR32_SORT2(LT,X0,X1) CAT(_VECTOR32_SORT2_,LT(X0,X1))(X0,X1)
#define _VECTOR32_SORT2_1(X0,X1) (X0,X1)
#define _VECTOR32_SORT2_0(X0,X1) (X1,X0)

#define _VECTOR32_SORT3(LT,X0,X1,X2) _VECTOR32_SORT3_MERGE(LT,UNWRAP2(_VECTOR32_SORT2(LT,X0,X1)),X2)
#define _VECTOR32_SORT3_MERGE(LT,V0,X2) _VECTOR32_SORT3_MERGE_A(LT,V0,X2)
#define _VECTOR32_SORT3_MERGE_A(LT,X0,X1,X2) CAT(_VECTOR32_SORT3_MERGE_A,LT(X0,X2))(LT,X0,X1,X2)
#define _VECTOR32_SORT3_MERGE_A1(LT,X0,X1,X2) CAT(_VECTOR32_SORT3_MERGE_B,LT(X1,X2))(LT,X0,X1,X2)
#define _VECTOR32_SORT3_MERGE_A0(LT,X0,X1,X2) (X2,X0,X1)
#define _VECTOR32_SORT3_MERGE_B1(LT,X0,X1,X2) (X0,X1,X2)
#define _VECTOR32_SORT3_MERGE_B0(LT,X0,X1,X2) (X0,X2,X1)

#define _VECTOR32_SORT4(LT,X0,X1,X2,X3)\
  _VECTOR32_SORT4_MERGE(LT,UNWRAP2(_VECTOR32_SORT2(LT,X0,X1)),UNWRAP2(_VECTOR32_SORT2(LT,X2,X3)))
#define _VECTOR32_SORT4_MERGE(LT,V0,V1)\
  _VECTOR32_SORT4_MERGE_A(LT,V0,V1)
#define _VECTOR32_SORT4_MERGE_A(LT,X0,X1,X2,X3)/*((->X0,X1),(->X2,X3))*/\
  CAT(_VECTOR32_SORT4_MERGE_A,LT(X0,X2))(LT,X0,X1,X2,X3)
#define _VECTOR32_SORT4_MERGE_A1(LT,X0,X1,X2,X3)/*((X0,->X1),(->X2,X3))*/\
  CAT(_VECTOR32_SORT4_MERGE_B,LT(X1,X2))(LT,X0,X1,X2,X3)
#define _VECTOR32_SORT4_MERGE_A0(LT,X0,X1,X2,X3)/*((X2,->X0,X1),(->X3))*/\
  CAT(_VECTOR32_SORT4_MERGE_XA,LT(X0,X3))(LT,X0,X1,X2,X3)
#define _VECTOR32_SORT4_MERGE_B1(LT,X0,X1,X2,X3)/*((X0,X1,->X2),(->X3))*/\
  (X0,X1,X2,X3)
#define _VECTOR32_SORT4_MERGE_B0(LT,X0,X1,X2,X3)/*((X0,X2,->X1),(->X3))*/\
  CAT(_VECTOR32_SORT4_MERGE_C,LT(X1,X3))(LT,X0,X1,X2,X3)
#define _VECTOR32_SORT4_MERGE_C1(LT,X0,X1,X2,X3)/*((X0,X2,X1,X3),())*/\
  (X0,X2,X1,X3)
#define _VECTOR32_SORT4_MERGE_C0(LT,X0,X1,X2,X3)/*((X0,X2,X3,X1),())*/\
  (X0,X2,X3,X1)
#define _VECTOR32_SORT4_MERGE_XA1(LT,X0,X1,X2,X3)/*((X2,X0,->X1),(->X3))*/\
  CAT(_VECTOR32_SORT4_MERGE_XB,LT(X1,X3))(LT,X0,X1,X2,X3)
#define _VECTOR32_SORT4_MERGE_XA0(LT,X0,X1,X2,X3)/*((X2,X3,X0,X1),())*/\
  (X2,X3,X0,X1)
#define _VECTOR32_SORT4_MERGE_XB1(LT,X0,X1,X2,X3)/*((X2,X0,X1,X3),())*/\
  (X2,X0,X1,X3)
#define _VECTOR32_SORT4_MERGE_XB0(LT,X0,X1,X2,X3)/*((X2,X0,X3,X1),())*/\
  (X2,X0,X3,X1)

#define _VECTOR32_SORT5(LT,X0,X1,X2,X3,X4)\
  _VECTOR32_SORT_MERGE(LT,_VECTOR32_SORT2(LT,X0,X1),_VECTOR32_SORT3(LT,X2,X3,X4),2,3,0,0)

#define _VECTOR32_SORT6(LT,X0,X1,X2,X3,X4,X5)\
  _VECTOR32_SORT_MERGE(LT,_VECTOR32_SORT3(LT,X0,X1,X2),_VECTOR32_SORT3(LT,X3,X4,X5),3,3,0,0)

#define _VECTOR32_SORT7(LT,X0,X1,X2,X3,X4,X5,X6)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT3(LT,X0,X1,X2),\
    _VECTOR32_SORT4(LT,X3,X4,X5,X6),\
    3,4,0,0)

#define _VECTOR32_SORT8(LT,X0,X1,X2,X3,X4,X5,X6,X7)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT4(LT,X0,X1,X2,X3),\
    _VECTOR32_SORT4(LT,X4,X5,X6,X7),\
    4,4,0,0)

#define _VECTOR32_SORT9(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT4(LT,X0,X1,X2,X3),\
    _VECTOR32_SORT5(LT,X4,X5,X6,X7,X8),\
    4,5,0,0)

#define _VECTOR32_SORT10(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT5(LT,X0,X1,X2,X3,X4),\
    _VECTOR32_SORT5(LT,X5,X6,X7,X8,X9),\
    5,5,0,0)

#define _VECTOR32_SORT11(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT5(LT,X0,X1,X2,X3,X4),\
    _VECTOR32_SORT6(LT,X5,X6,X7,X8,X9,X10),\
    5,6,0,0)

#define _VECTOR32_SORT12(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT6(LT,X0,X1,X2,X3,X4,X5),\
    _VECTOR32_SORT6(LT,X6,X7,X8,X9,X10,X11),\
    6,6,0,0)

#define _VECTOR32_SORT13(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT6(LT,X0,X1,X2,X3,X4,X5),\
    _VECTOR32_SORT7(LT,X6,X7,X8,X9,X10,X11,X12),\
    6,7,0,0)

#define _VECTOR32_SORT14(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT7(LT,X0,X1,X2,X3,X4,X5,X6),\
    _VECTOR32_SORT7(LT,X7,X8,X9,X10,X11,X12,X13),\
    7,7,0,0)

#define _VECTOR32_SORT15(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT7(LT,X0,X1,X2,X3,X4,X5,X6),\
    _VECTOR32_SORT8(LT,X7,X8,X9,X10,X11,X12,X13,X14),\
    7,8,0,0)

#define _VECTOR32_SORT16(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT8(LT,X0,X1,X2,X3,X4,X5,X6,X7),\
    _VECTOR32_SORT8(LT,X8,X9,X10,X11,X12,X13,X14,X15),\
    8,8,0,0)

#define _VECTOR32_SORT17(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT8(LT,X0,X1,X2,X3,X4,X5,X6,X7),\
    _VECTOR32_SORT9(LT,X8,X9,X10,X11,X12,X13,X14,X15,X16),\
    8,9,0,0)

#define _VECTOR32_SORT18(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT9(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8),\
    _VECTOR32_SORT9(LT,X9,X10,X11,X12,X13,X14,X15,X16,X17),\
    9,9,0,0)

#define _VECTOR32_SORT19(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT9(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8),\
    _VECTOR32_SORT10(LT,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18),\
    9,10,0,0)

#define _VECTOR32_SORT20(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT10(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9),\
    _VECTOR32_SORT10(LT,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19),\
    10,10,0,0)

#define _VECTOR32_SORT21(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT10(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9),\
    _VECTOR32_SORT11(LT,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20),\
    10,11,0,0)

#define _VECTOR32_SORT22(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT11(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10),\
    _VECTOR32_SORT11(LT,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21),\
    11,11,0,0)

#define _VECTOR32_SORT23(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT11(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10),\
    _VECTOR32_SORT12(LT,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22),\
    11,12,0,0)

#define _VECTOR32_SORT24(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT12(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11),\
    _VECTOR32_SORT12(LT,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23),\
    12,12,0,0)

#define _VECTOR32_SORT25(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT12(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11),\
    _VECTOR32_SORT13(LT,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24),\
    12,13,0,0)

#define _VECTOR32_SORT26(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT13(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12),\
    _VECTOR32_SORT13(LT,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25),\
    13,13,0,0)

#define _VECTOR32_SORT27(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT13(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12),\
    _VECTOR32_SORT14(LT,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26),\
    13,14,0,0)

#define _VECTOR32_SORT28(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT14(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13),\
    _VECTOR32_SORT14(LT,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27),\
    14,14,0,0)

#define _VECTOR32_SORT29(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT14(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13),\
    _VECTOR32_SORT15(LT,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28),\
    14,15,0,0)

#define _VECTOR32_SORT30(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28,X29)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT15(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14),\
    _VECTOR32_SORT15(LT,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28,X29),\
    15,15,0,0)

#define _VECTOR32_SORT31(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28,X29,X30)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT15(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14),\
    _VECTOR32_SORT16(LT,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28,X29,X30),\
    15,16,0,0)

#define _VECTOR32_SORT32(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28,X29,X30,X31)\
  _VECTOR32_SORT_MERGE(\
    LT,\
    _VECTOR32_SORT16(LT,X0,X1,X2,X3,X4,X5,X6,X7,X8,X9,X10,X11,X12,X13,X14,X15),\
    _VECTOR32_SORT16(LT,X16,X17,X18,X19,X20,X21,X22,X23,X24,X25,X26,X27,X28,X29,X30,X31),\
    16,16,0,0)


#define _VECTOR32_SORT_MERGE(LT,V0,V1,LI,LJ,I,J,...)\
  _VECTOR32_SORT_MERGE_EVAL(_VECTOR32_SORT_MERGE_X(LT,V0,V1,LI,LJ,I,J __VA_OPT__(,)__VA_ARGS__))
#define _VECTOR32_SORT_MERGE_X(LT,V0,V1,LI,LJ,I,J,...)\
  CAT_ALL(_VECTOR32_SORT_MERGE_X,DEC5_GEQ(I,LI),DEC5_GEQ(J,LJ))(LT,V0,V1,LI,LJ,I,J __VA_OPT__(,)__VA_ARGS__)
#define _VECTOR32_SORT_MERGE_X11(LT,V0,V1,LI,LJ,I,J,...)\
  (__VA_ARGS__)
#define _VECTOR32_SORT_MERGE_X10(LT,V0,V1,LI,LJ,I,J,...)\
  TUPLE_CONCAT((__VA_ARGS__),TUPLE_DROP_DEC5(V1,J))
#define _VECTOR32_SORT_MERGE_X01(LT,V0,V1,LI,LJ,I,J,...)\
  TUPLE_CONCAT((__VA_ARGS__),TUPLE_DROP_DEC5(V0,I))
#define _VECTOR32_SORT_MERGE_X00(LT,V0,V1,LI,LJ,I,J,...)\
  _VECTOR32_SORT_MERGE_Y(LT,V0,V1,TUPLE_NTH_DEC5(V0,I),TUPLE_NTH_DEC5(V1,J),LI,LJ,I,J __VA_OPT__(,)__VA_ARGS__)
#define _VECTOR32_SORT_MERGE_Y(LT,V0,V1,X,Y,LI,LJ,I,J,...)\
  CAT(_VECTOR32_SORT_MERGE_Y,LT(X,Y))(LT,V0,V1,X,Y,LI,LJ,I,J __VA_OPT__(,)__VA_ARGS__)
#define _VECTOR32_SORT_MERGE_Y1(LT,V0,V1,X,Y,LI,LJ,I,J,...)\
  DEFER(_VECTOR32_SORT_MERGE_I)()(LT,V0,V1,LI,LJ,DEC5_ADD(I,1),J __VA_OPT__(,)__VA_ARGS__,X)
#define _VECTOR32_SORT_MERGE_Y0(LT,V0,V1,X,Y,LI,LJ,I,J,...)\
  DEFER(_VECTOR32_SORT_MERGE_I)()(LT,V0,V1,LI,LJ,I,DEC5_ADD(J,1) __VA_OPT__(,)__VA_ARGS__,Y)
#define _VECTOR32_SORT_MERGE_I()\
  _VECTOR32_SORT_MERGE_X
#define _VECTOR32_SORT_MERGE_EVAL(X)\
  _VECTOR32_SORT_MERGE_EVAL1(_VECTOR32_SORT_MERGE_EVAL1(_VECTOR32_SORT_MERGE_EVAL1(_VECTOR32_SORT_MERGE_EVAL1(X))))
#define _VECTOR32_SORT_MERGE_EVAL1(X)\
  _VECTOR32_SORT_MERGE_EVAL2(_VECTOR32_SORT_MERGE_EVAL2(_VECTOR32_SORT_MERGE_EVAL2(_VECTOR32_SORT_MERGE_EVAL2(X))))
#define _VECTOR32_SORT_MERGE_EVAL2(X)\
  X

#endif
